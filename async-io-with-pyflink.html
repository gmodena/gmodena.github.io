<!DOCTYPE html>
<html lang="en">
  <head>
    <script async defer data-domain="nowave.it" src="https://plausible.io/js/plausible.js"></script>
    <link href='http://fonts.googleapis.com/css?family=Noticia+Text:400,700' rel='stylesheet' type='text/css' />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title> Async I/O with PyFlink | nowave.it </title>
    <link rel="stylesheet" href="./theme/css/style.css" type="text/css" />
    <link rel="stylesheet" href="./theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="./theme/css/font-awesome.css" type="text/css"/>
  </head>
  <body>
    <div class=container>
<div class="header">
    <a href="./">nowave.it</a> <span class="muted"></span>
</div>

<div class=navigation>
    <ul>
    </ul>
</div>
<div class=separator></div>        
        <div class=body>
    <h1 class="title"> Async I/O with PyFlink</h1>
    <p class=date> di 07 mei 2024 </p>
    <p>This article contains notes on the implementation of asynchronous callbacks in PyFlink. The work is derived from a collaboration with <a href="https://m.mediawiki.org/wiki/Platform_Engineering_Team/Event_Platform_Value_Stream">Wikimedia's Platform team</a> and <a href="https://www.tngtech.com/en/index.html">TNG</a>, and further developed in a <a href="https://doc.wikimedia.org/data-engineering/eventutilities-python/">hosted Flink solution</a>.</p>
<p>Code snippets in this article have not been tested. They should be treated more like pseduo code than as a reference.</p>
<h2>Introduction</h2>
<p>When developing streaming applications, we sometimes need asynchronous access to external data sources. For instance, we might want to perform a lookup join on a database or query a microservice.</p>
<p>At the time of writing, <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/operators/asyncio/">Async I/O</a> in Apache Flink is only supported by the Java API. Making an external call in a Python application results in a synchronous, blocking operation.</p>
<p>This article describes an approach to asynchronous computation in PyFlink, based on mini-batching. Events are processed concurrently with a thread pool local to a <code>KeyedProcessFunction</code> operator.</p>
<h2>Mini batching with count + time window triggers</h2>
<p>Mini batching can be implemented using a window function and an operator that consumes all elements of the window and yields back an arbitrary number of records. An approach that worked well in practice is to use a window governed by a "count with time" trigger. A batch is considered complete when either one of these conditions are met:</p>
<ol>
<li>
<p>The window has processed a number of records equal to a <code>batch_size</code> parameter.</p>
</li>
<li>
<p>A time interval of length <code>batch_duration</code> has elapsed.</p>
</li>
</ol>
<p>Adding a time bound avoids a batch staying open indefinitely. This would be the case when the record count is low (e.g. if data distribution in a partitioned <code>DataStream</code> is skewed).</p>
<h2>Timers</h2>
<p>Flink provides a timer mechanism, that can be registered by an operator.  A <code>ProcessFunction</code> can use timers to trigger actions at specific times. Timers can be either <strong>processing time</strong> timers  or <strong>event time</strong> timers,  which are triggered by watermarks.</p>
<p>When the specified processing time or the event-time watermark reaches the specified event time, , <code>ProcessFunction.on_timer</code>  is triggered.</p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.18/api/java/org/apache/flink/streaming/api/functions/KeyedProcessFunction.html"><code>KeyedProcessFunction</code></a> is a commonly used function to work with timers.</p>
<h2>Implementation</h2>
<p>A straightforward implementation can subclass <code>KeyedProcessFunction</code> , initialize a thread pool, and implement window triggering logic in <code>on_timer</code> and <code>process_element</code> methods. In the reminder of this article we'll do to the following:</p>
<ol>
<li>We use a <code>ThreadPoolExecutor</code> from <a href="https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures"><code>concurrent.futures</code></a> to launch parallel tasks. </li>
<li>A <code>KeyProcessFunction.process_element</code> implementation consumes incoming records, and submits futures to the executor thread pool. Once <code>batch_size</code> records have been consumed, futures are collected and the current window is closed. When <code>process_element</code> is invoked and no future has been scheduled, a timer is registered in the Flink Timer Registry. The timer will trigger at <code>current_time + batch_duration</code> (expressed in milliseconds).</li>
<li><code>KeyProcessFunction.on_timer</code> is triggered when the window timeout is reached and the timer registered in <code>process_element</code> fires. Any pending future is collected and the current window is closed. <sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> </li>
</ol>
<p>A basic implementation would look like the following:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_worker</span> <span class="o">=</span> <span class="n">max_worker</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">executor</span><span class="p">:</span> <span class="n">ThreadPoolExecutor</span>
    <span class="c1"># timestamp that determines when a timer will be triggered, ending the window.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># batch_futures keeps track of futures scheduled</span>
    <span class="c1"># during a window lifetime.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Future</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">executor</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_workers</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_timer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">timestamp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="s2">&quot;KeyedProcessFunction.OnTimerContext&quot;</span><span class="p">):</span> 
    <span class="c1"># collect elements</span>
    <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">collect_batch</span><span class="p">()</span>

    <span class="c1"># when the timer fires, reset the batch.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">process_element</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">event</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="n">KeyedProcessFunction</span><span class="o">.</span><span class="n">Context</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
    <span class="c1"># batch_futures is empty, meaning we are starting a new batch here.</span>
    <span class="c1"># start a timer for this batch.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">current_processing_time</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_duration_ms</span>
        <span class="p">)</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">register_processing_time_timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span><span class="p">)</span>

     <span class="c1"># Run func in an executor thread, and add the (future, input event) tuple to the batch.</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">,</span> <span class="n">event</span><span class="p">),</span> <span class="n">event</span><span class="p">))</span>

     <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
        <span class="c1"># The batch is full. Cancel the outstanding batch timer,</span>
        <span class="c1"># collect and emit the results.</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">delete_processing_time_timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span><span class="p">)</span>
        <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">collect_batch</span><span class="p">()</span>
        <span class="c1"># close the count window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">collect_batch</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">future</span><span class="p">,</span> <span class="n">event</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">result</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div>

<h2>Delivery guarantees</h2>
<p>This implementation would not be able to satisfy <code>EXACTLY_ONCE</code> delivery guarantees. Upon application restarts, events processed since the last checkpoint would be re-processed.</p>
<p>To ensure <code>EXACTLY_ONCE</code> (for the Flink side of a streaming application), we can keep a list of events that have already been processed in the current window in a <a href="https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/api/common/state/ListState.html">ListState</a>. The <code>ListState</code> is checkpointed consistently by Flink as part of the its distributed snapshots implementation. While this will mitigate duplicate event processing (e.g. calls to api), the guarantee holds within a single window firing and not between windows firing: when resuming from a checkpoint (e.g. recovery), source offsets (and list state) will rewind to the latest known checkpoint.</p>
<p>A basic implementation would look like the following:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">open</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Keep a list of events that have already been processed in the current window,</span>
        <span class="c1"># to mitigate duplicate event processing (e.g. calls to api) in case of application</span>
        <span class="c1"># restarts. This is guaranteed within a single window firing</span>
        <span class="c1"># and not between windows firing: when resuming from a checkpoint (e.g. recovery)</span>
        <span class="c1"># source offsets (and list state) will rewind to the latest known checkpoint.</span>
        <span class="c1"># The list state is check pointed consistently by the system as part of the</span>
        <span class="c1"># distributed snapshots.</span>
        <span class="c1"># The ListState could grow large in size. For book-keeping, we clean() it once all events in a batch</span>
        <span class="c1"># have been processed.</span>
        <span class="n">event_type_info</span> <span class="o">=</span> <span class="n">Types</span><span class="o">.</span><span class="n">PICKLED_BYTE_ARRAY</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state_descriptor</span> <span class="o">=</span> <span class="n">ListStateDescriptor</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;list&quot;</span><span class="p">,</span> <span class="n">elem_type_info</span><span class="o">=</span><span class="n">event_type_info</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state</span><span class="p">:</span> <span class="n">ListState</span> <span class="o">=</span> <span class="n">runtime_ctx</span><span class="o">.</span><span class="n">get_list_state</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state_descriptor</span>
        <span class="p">)</span>

<span class="k">def</span> <span class="nf">process_element</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">event</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">ctx</span><span class="p">:</span> <span class="s2">&quot;KeyedProcessFunction.Context&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="c1"># batch_futures is empty, meaning we are starting a new batch here.</span>
        <span class="c1"># start a timer for this batch.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">current_processing_time</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_duration_ms</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">register_processing_time_timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span><span class="p">)</span>
    <span class="c1"># Run func in an executor thread, and add the (future, input event)</span>
    <span class="c1"># tuple to the batch</span>
     <span class="n">processed_events</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
     <span class="k">if</span> <span class="ow">not</span> <span class="n">processed_events</span> <span class="ow">or</span> <span class="n">event</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">processed_events</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">executor</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">,</span> <span class="n">event</span><span class="p">)))</span>

     <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
        <span class="c1"># The batch is full. Cancel the outstanding batch timer</span>
        <span class="c1"># and collect and emit the results.</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">timer_service</span><span class="p">()</span><span class="o">.</span><span class="n">delete_processing_time_timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trigger_timestamp</span><span class="p">)</span>

        <span class="k">yield from</span> <span class="bp">self</span><span class="o">.</span><span class="n">collect_batch</span><span class="p">()</span>
        <span class="c1"># close the count window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># All events have been processed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">collect_batch</span><span class="p">():</span>
    <span class="c1"># Iterate over the completed futures according to their insertion order.</span>
    <span class="c1"># `batch_futures` now contains both done and uncompleted futures returned</span>
    <span class="c1"># by wait().</span>
    <span class="k">for</span> <span class="n">future</span><span class="p">,</span> <span class="n">event</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_futures</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="c1"># handle errors</span>
            <span class="k">yield</span> <span class="n">result</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># handle errors</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">processed_events_state</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>  <span class="c1"># mark the event as processed</span>
</code></pre></div>

<h1>Conclusion</h1>
<p>This article showed an approach to execute async functions on a Flink DataStream by introducing ad-hoc windowing logic and a local thread pool.</p>
<h1>References</h1>
<ul>
<li>https://www.alibabacloud.com/help/en/flink/use-cases/best-practices-for-using-timers-in-datastream</li>
<li>https://gitlab.wikimedia.org/repos/data-engineering/eventutilities-python/-/blob/main/docs/DESIGN.md?ref_type=heads#asynchronous-http-callback-via-datastream-minibatching</li>
<li>https://gitlab.wikimedia.org/repos/data-engineering/eventutilities-python/-/blob/main/eventutilities_python/stream/manager.py?ref_type=heads#L589</li>
</ul>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>we should consider extracting this logic out of a <code>ProcessFunction</code> and move it to a <a href="https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/streaming/api/windowing/triggers/Trigger.html">Trigger</a>.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
    
        </div>
        
<div class=footer>
   <div class="contact">
      <p>
        &raquo;
        <a href="mailto:gm@nowave.it">gm@nowave.it</a> |
        <a href="http://github.com/gmodena" target="_blank">github.com/gmodena</a> |
        <a href="https://hachyderm.io/@gmodena" target="_blank">https://hachyderm.io/@gmodena</a>
        &laquo;
      </p>
    </div>
  <p>&copy; Copyright <script language="JavaScript">var date = new Date(); document.write(date.getFullYear());</script> by Gabriele Modena</p>
  <p>  
    <a href="https://github.com/fjavieralba/flasky">Theme</a>  by <a href="http://fjavieralba.com">fjavieralba</a> (Modified)
  </p> 
<!--
  <p>
    <div class=social style="font-size: 27px;">
      <ul>
        <script language="JavaScript">
          u = '';
          s = '';
          document.write('<a href=\"mailto:' + u + '@' + s + '\" target=\"_blank\">');
        </script>
            <li><i class="icon-envelope icon-large"></i> </li>
        </a>
        <a href="http://twitter.com/" target="_blank"> <li> <i class="icon-twitter-sign icon-large"> </li></i> </a>
        <a href="" target="_blank"><li><i class="icon-linkedin-sign icon-large" ></i></li></a>
        <a href="" target="_blank"> <li> <i class="icon-github-sign icon-large"></i> </li> </a>
        <a href="" target="_blank"><li> <i class="icon-facebook-sign icon-large"></i></li> </a>
        <a href="" target="_blank"><li><i class="icon-google-plus-sign icon-large"></i> </li> </a>
        <a href="" target="_blank"><li><i class="icon-pinterest-sign icon-large"></i></li></a>


        <a href="./feeds/all.rss.xml" rel="alternate" title="Recent Blog Posts"><li> <i class="icon-rss icon-large"></i> </li></a>
      </ul>
    </div>
  </p>
-->
</div>    </div>
  </body>
</html>
